## 自动驾驶入门课程第⑤讲 — 感知（下）

# 一句话总结内容

通过卷积神经网络实现，检测，分类，跟踪，分割；使用卡尔曼滤波进行传感器数据融合

# **卷积神经网络CNN**

**卷积神经网络CNN**是一种人工神经网络，它对感知问题特别有效，CNN接受多维输入包括定义大多数传感器数据的二维和三维形状。如果使用标准神经网络对图像进行分类，则需要通过一种方法将图像连接到网络的第一层，这属于一维。标准做法是通过将图像矩阵重塑为一个矢量，并在一个大行中连接所有列，将图像“展开”为一维像素阵列。



![图片](https://mmbiz.qpic.cn/mmbiz_jpg/C4wVziccAsSJTIRCNmN9XRMODLHFDiaPrAECbYWg1ppxgCsnzibrJAEyRkhwFbgNLKcrpWaTKsIdYX1oPlle5ushA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



然而这种方法打破了图像中所嵌入的空间信息，如果图像中有车轮，则车轮中的所有像素将散布在整个像素阵列中。如果将其散布在一个维度上，神经网络很难从图像中提取车轮。CNN通过维持输入像素之间的空间关系来解决这个问题，CNN通过将过滤器连续滑过图像来收集信息，<u>每次收集信息时，只对整个图像的一小部分区域进行分析，称为**卷积**。</u>

。



![图片](https://mmbiz.qpic.cn/mmbiz_jpg/C4wVziccAsSJTIRCNmN9XRMODLHFDiaPrA2RMdUnhI6Bbrib6Y8POlLKfSpgUiboHZmhKfp2tv2QpAUPxX7CMibNR6g/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



当在整个输入图像上对一个过滤器进行卷积时，将该信息与下一个卷积层相关联。例如CNN识别第一个卷积层中的基本边缘和颜色信息，然后通过在第一层上卷积新过滤器，CNN使用边缘和颜色信息来归纳更复杂的结构如车轮、车门、挡风玻璃；而另一个卷积可使用车轮、车门、挡风玻璃识别整个车辆；最后神经网络可使用这一高阶信息对车辆进行分类。



![图片](https://mmbiz.qpic.cn/mmbiz_jpg/C4wVziccAsSJTIRCNmN9XRMODLHFDiaPrAAHv4T79PAG35SibmicXrPYp3KrEHSZqSibudpibwwfNQYX6RBMoj1mxuWQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



CNN根据其任务查找真正需要的特征，任务可能是图像检测、分类、分割、其他类型的目标。



## **检测与分类**

无人驾驶中，使用什么算法来对障碍物进行检测和分类？可以先使用**检测CNN**来查找图像中的对象的位置，在对图像中的对象进行定位后，可以将图像发送给另一个CNN进行分类。也可以使用单一CNN体系结构对对象进行检测和分类，一种通常的做法为在单个网络体系结构的末端附加几个不同的“头”，一个头可能执行检测，另一个则可能执行分类。经典体系结构为 R-CNN、Fast R-CNN、Faster R-CNN、YOLO、SSD等。

## **跟踪**

跨帧追踪对象会带来哪些好处？

- 首先追踪在检测失败时是至关重要的，如果你在运行检测算法时，对象被其他对象遮挡一部分，则检测算法可能会失败，但追踪可以解决遮挡问题。
- 另一个原因在于追踪可以保留身份

## 分割

语义分割涉及对图像的每个像素进行分类，用于尽可能详细地了解环境并确定车辆可驾驶区域。



![图片](https://mmbiz.qpic.cn/mmbiz_jpg/C4wVziccAsSJTIRCNmN9XRMODLHFDiaPrAg2cfxHibKK5qmibBTkv1R76vrAVsyF0oRKwfwqRwSCAdUFFkUjAWGLSQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



语义分割依赖于一种特殊类型的CNN，被称为**全卷积网络FCN**。FCN用卷积层来替代传统CNN体系结构末端的平坦层，现在网络中的每一层都是卷积层，因此名称为“**全卷积网络**”。



FCN提供了可在原始输入图像之上叠加的逐像素输出，必须考虑的一个复杂因素是大小。在典型的CNN中经过多次卷积之后所产生的输出比原始输入图像小得多。然而为了分割像素，输出尺寸必须与原始图像的尺寸相匹配。为了完成，可以对中间输出进行上采样处理，直到最终输出的大小与原始输出图像的大小相匹配。网络的前半部分通常被称为**编码器**，因为这部分网络对输入图像的特征进行了提取和编码。网络的后半部分通常被称为**解码器**，因为它对这些特征进行了解码并将其应用于输出。



![图片](https://mmbiz.qpic.cn/mmbiz_jpg/C4wVziccAsSJTIRCNmN9XRMODLHFDiaPrA1iciaT09iceribDgRbnHWxs03xxGtwXl9vLLGVMMEQiaqX1wrA7nFvkLUsQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

# **感知**

使用 **YOLO 网络**来检测车道线、动态物体其中包括车辆、卡车、骑自行车的人、行人。

**虚拟车道（VL**）

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200523185430233.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1amlhbmluZ18xMTAxMTc=,size_16,color_FFFFFF,t_70)

绿色曲线是的算法生成的VL



在线检测模块会并入来自其他传感器的数据对车道线预测进行调整，车道线最终被并入名为“虚拟车道”的单一数据结构中

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/C4wVziccAsSJTIRCNmN9XRMODLHFDiaPrAQDvpibCyYtmcniaM2vuibD4kFSV42U5IU58vibcdGR4kqukVHbWFhJV75Q/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

## **传感器数据比较**

**摄像头：**非常适用于分类，主要用于交通信号灯分类、车道检测

**激光雷达：**优势在于障碍物检测

**雷达：**：在探测范围和应对恶劣天气方面占优势

通过融合这三种传感器的数据可实现最佳聚合性能，被称为“**传感器融合**”。

## **感知融合策略**

激光雷达和雷达来检测障碍物，用于融合输出的主要算法为**卡尔曼滤波**

卡尔曼滤波有两个步骤：第一步为预测状态，第二步是更新测量结果。

**卡尔曼滤波有两个步骤**：

- 第一步为预测状态，第二步是更新测量结果。设想正在跟踪一名行人，这里的状态表示行人的位置和速度，从已经掌握的行人状态开始，使用这些信息来执行卡尔曼滤波的第一步，即预测行人在将来的状态；
- 下一步为误差结果更新，使用新的传感器来更新所认为的行人状态，卡尔曼滤波算法是预测和更新步骤的无限循环。

Predict State 预测状态

Update Measurement 更新测量结果

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/C4wVziccAsSJTIRCNmN9XRMODLHFDiaPrAQpaINk0Wicms5HRxDUibSLeBr07wQuwHichM0pFDx9OvCOWpH7KqQ409g/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

实际上有两种测量结果更新步骤：同步和异步。同步融合同时更新来自不同传感器的测量结果，而异步融合则逐个更新所收到的传感器测量结果。传感器融合可提高感知性能，因为各传感器相辅相成，融合也可以减少跟踪误差。